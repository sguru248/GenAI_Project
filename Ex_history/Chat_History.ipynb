{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Message History\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n",
    "\n",
    "\n",
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am Siva and I am Developer\")],\n",
    "    config = config\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name = \"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "\n",
    "config3 = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content =\"Hi my name is Guru\")],\n",
    "    config = config3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mpre complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the question to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name = \"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model\n",
    "\n",
    "\n",
    "\n",
    "##n make more complicate\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key = \"messages\")\n",
    "\n",
    "\n",
    "config4 = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, my name is sivaGuru \")], \"language\":\"Tamil\"},\n",
    "    config = config4\n",
    "    )\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manage Chat History  ### (trim_messages)\n",
    "\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 75,\n",
    "    strategy=\"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're the good Assistant\"),\n",
    "    HumanMessage(content=\"hi, i'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"hi, I like venilla ice cream\"),\n",
    "    AIMessage(content=\"Nice\"),\n",
    "    HumanMessage(content=\"What is 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"No problems!\"),\n",
    "    HumanMessage(content=\"Having fun!\"),\n",
    "    AIMessage(content=\"Yes!\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "trimmer.invoke(messages)\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config= {\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\" : messages + [HumanMessage(content=\"What is my name?\")],\n",
    "    \"language\" : \"English\"  \n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
